---
title: 08-分片
url: https://www.yuque.com/gaollard/efekv4/hgxy0q
---



### 1. 分片设置

    #分片设置如下
    PUT /索引库名称/_settings
    {
      "number_of_shards": 1,
      "number_of_replicas": 4
    }

<!---->

    PUT /clayindex
    {
       "settings": {
        "number_of_shards": 2,      #主分片数量是2
        "number_of_replicas": 1     #副本分片数量是1
       }, 
       "mappings": {
         "properties": {
         "name":{
           "type": "keyword"
         },
         "address":{
            "type": "text"
         },
         "age":{
            "type": "integer"
         }
         }
       }
    }

在创建索引映射的时候，可以在settings参数中指定分片数量。需要注意的是，如果有索引已经建立，那么修改的时候只能修改副本分片的数量，主分片数量不可以修改



### 2. 多少个分片数量才合理

**1. 避免分片过大**

因为这样会对集群“从故障中恢复”造成不利的影响。尽管并没有关于分片大小的固定限值，但是开发和运维人员通常将50GB作为分片上限，而且这一限值在各种用例中都已得到了验证。

**2. 分片不可过小**

分片过小会导致“段”（Segment，Elasticsearch中存储数据的空间块）过小，进而导致开销增加。用户要尽量将分片的平均大小控制在几GB到几十GB。对于时序型数据而言，分片大小通常介于20GB～40GB。

**3. 文档归并**

由于单个分片的开销取决于“段”的数量和“段”的大小，因此通过文档归并（forcemerge）操作强制将较小的“段”合并为较大的“段”。这样做能够减少开销并改善查询的性能。理想状况下，应当在索引内无数据写入的时候完成此操作。但是需要注意的是，文档归并操作是一个极其耗费资源的操作，所以应该在非高峰时段进行。

**4. 分片数量限制**

每个节点上可以存储的分片数量与可用的堆内存大小成正比，但是Elasticsearch并未强制规定固定限值。推荐将单个分片存储索引数据的大小控制在20GB左右，绝对不要超过50GB，分片的数量可以根据如下公式计算：

    分片数量=数据总量 / 20GB



### 3. 数据存储分片机制应对扩容和分片故障的方式

如图10-11所示，集群中有3个主分片，3个副本分片，每个主分片对应一个副本分片，而且主分片和副本分片分布在不同的节点。

所以当集群中内任何一个节点出现问题的时候，我们的数据都完好无损。当我们写入文档时，这些文档都会保存在主分片上，然后被并行地复制到对应的副本分片上。

这样就保证了既可以从主分片上获得文档数据，又可以从副本分片上获得文档数据，也提高了查询效率。

![](https://s3.airtlab.com/elasticsearch/20220430214308.png)

当新加入Node3节点对集群进行扩容时，Node1和Node2上各有一个分片被迁移到了新的Node 3节点上。此时，每个节点上都拥有两个分片，而不是之前的3个分片。这样每个节点的硬件资源将被更少的分片所使用，每个分片的性能将会得到提升。

![](https://s3.airtlab.com/elasticsearch/20220430214430.png)

我们发现，Node1和Node2组合后的分片是（R0,R1,P1,P2），Node1和Node3组合后的分片是（R2,P0,P1,P2），Node2和Node3组合后的分片是（R0,R1,P0,R2）。所以当这3个节点中有任何一个节点出现异常时，其余两个节点中的分片都完整地保留了分片0、分片1、分片2的数据。也就是说，当出现任何一个节点宕机时，也不会导致服务异常，只不过新的主节点会把副本分片提升为主分片。但是当出现两个节点同时出现异常时，则此集群状态就不能正确提供服务，因为集群数据不完整。
